{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Inception bottleneck features\n",
    "From raw image, get 2048 features of the penultimate Inception v3 layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import _pickle as pickle\n",
    "from os import listdir\n",
    "from os.path import join, isfile\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "from keras import backend as K\n",
    "K.set_session(session)\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical, plot_model\n",
    "\n",
    "from keras.applications import xception\n",
    "from keras.applications import inception_v3\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(img_id, train_or_test, size=None):\n",
    "    img = image.load_img(join(data_dir, train_or_test, '%s.jpg' % img_id), target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all train images: 10222\n",
      "Train data has 120 classes.\n",
      "Number of all test images: 10357\n",
      "y_tr shape: (8185, 120)\n",
      "y_val shape: (2037, 120)\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 120\n",
    "SEED = 1993\n",
    "np.random.seed(seed=SEED)\n",
    "data_dir = '../data'\n",
    "\n",
    "labels = pd.read_csv(join(data_dir, 'labels.csv'))\n",
    "print('Number of all train images: {}'.format(len(labels)))\n",
    "print(\"Train data has {} classes.\".format(len(labels.groupby('breed').count())))\n",
    "assert len(labels.groupby('breed').count()) == NUM_CLASSES, 'Number of classes in training set is not 120!'\n",
    "\n",
    "sample_submission = pd.read_csv(join(data_dir, 'sample_submission.csv'))\n",
    "print('Number of all test images: {}'.format(len(sample_submission)))\n",
    "\n",
    "# Split to train and validation sets\n",
    "l_val = labels.groupby('breed').apply(pd.DataFrame.sample, frac=0.2).reset_index(drop=True)\n",
    "l_tr = labels.loc[~labels['id'].isin(l_val['id'])]\n",
    "l_tr_index = {label:i for i,label in enumerate(np.unique(l_tr.breed))}\n",
    "l_tr_temp = [l_tr_index[label] for label in l_tr.breed]\n",
    "l_val_temp = [l_tr_index[label] for label in l_val.breed]\n",
    "y_tr = to_categorical(l_tr_temp ,num_classes=120)\n",
    "y_val = to_categorical(l_val_temp ,num_classes=120)\n",
    "print('y_tr shape: {}'.format(y_tr.shape))\n",
    "print('y_val shape: {}'.format(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from ../data//train//xs_bf_inception_v3\n",
      "xs_bf shape: (10222, 2049) size: 20,944,878\n",
      "Train bottleneck features shape: (8185, 2048) size: 16,762,880\n",
      "Validation bottleneck features shape: (2037, 2048) size: 4,171,776\n"
     ]
    }
   ],
   "source": [
    "# Get bottelneck features\n",
    "INPUT_SIZE = 299\n",
    "POOLING = 'avg'\n",
    "filename = data_dir + '//train//xs_bf_inception_v3'\n",
    "\n",
    "if isfile(filename):\n",
    "    # Load from file\n",
    "    print('Loading from {}'.format(filename))\n",
    "    with open(filename, 'rb') as fp:\n",
    "        xs_bf = pickle.load(fp)\n",
    "    print('xs_bf shape: {} size: {:,}'.format(xs_bf.shape, xs_bf.size))\n",
    "else:\n",
    "    # Preprocess images\n",
    "    print('Reading from raw images')\n",
    "    xs = np.zeros((len(labels), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "    for i, img_id in enumerate(labels['id']):\n",
    "        img = read_img(img_id, 'train', (INPUT_SIZE, INPUT_SIZE))\n",
    "        x = xception.preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "        xs[i] = x\n",
    "    print('All train Images shape: {} size: {:,}'.format(xs.shape, xs.size))\n",
    "    \n",
    "    # Predict\n",
    "    preprocess_bottleneck = inception_v3.InceptionV3(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "    xs_bf_raw = preprocess_bottleneck.predict(xs, batch_size=6, verbose=1)\n",
    "    print('All train bottleneck features shape: {} size: {:,}'.format(xs_bf_raw.shape, xs_bf_raw.size))\n",
    "    xs_bf = pd.concat([labels.id, pd.DataFrame(xs_bf_raw)], axis=1)\n",
    "    \n",
    "    # Save into file\n",
    "    print('Dumping into {}'.format(filename))\n",
    "    with open(filename, 'wb') as fp:\n",
    "        pickle.dump(xs_bf, fp)\n",
    "\n",
    "# Split to train/val sets\n",
    "x_tr = np.zeros((len(l_tr), xs_bf.shape[1]-1), dtype='float32')\n",
    "for i, img_id in enumerate(l_tr['id']):\n",
    "    x_tr[i] = xs_bf[xs_bf.id == img_id].values[0][1:]\n",
    "print('Train bottleneck features shape: {} size: {:,}'.format(x_tr.shape, x_tr.size))\n",
    "\n",
    "x_val = np.zeros((len(l_val), xs_bf.shape[1]-1), dtype='float32')\n",
    "for i, img_id in enumerate(l_val['id']):\n",
    "    x_val[i] = xs_bf[xs_bf.id == img_id].values[0][1:]\n",
    "print('Validation bottleneck features shape: {} size: {:,}'.format(x_val.shape, x_val.size))\n",
    "\n",
    "xs = None\n",
    "xs_bf = None\n",
    "xs_bf_raw = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  9.98022263e-01   3.33430635e-06   6.41821790e-06 ...,   2.00466861e-06\n",
      "    1.70796855e-05   1.13197382e-04]\n",
      " [  9.97948083e-01   5.11649216e-07   3.03720549e-06 ...,   4.03787823e-07\n",
      "    3.26681501e-06   7.20228699e-05]\n",
      " [  9.98273861e-01   2.32304813e-06   7.81836746e-06 ...,   6.27692988e-07\n",
      "    6.18255968e-06   4.16120111e-05]\n",
      " ..., \n",
      " [  8.84187837e-06   7.07727499e-06   1.58307535e-05 ...,   1.27004921e-06\n",
      "    2.01595811e-03   7.52225106e-01]\n",
      " [  4.21435113e-05   1.72687471e-05   1.82686194e-05 ...,   3.69871848e-06\n",
      "    2.91674248e-04   2.14446761e-01]\n",
      " [  3.74203494e-05   1.71298626e-05   2.99118362e-05 ...,   1.74821408e-05\n",
      "    6.13320915e-05   9.55419959e-01]]\n",
      "[   0.    0.    0. ...,  119.  102.  119.]\n",
      "Validation LogLoss 0.3684238395832664\n",
      "Validation Accuracy 0.8880706921944035\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression on bottleneck features\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\n",
    "logreg.fit(x_tr, (y_tr * range(NUM_CLASSES)).sum(axis=1))\n",
    "valid_probs = logreg.predict_proba(x_val)\n",
    "valid_preds = logreg.predict(x_val)\n",
    "print('Validation Xception LogLoss {}'.format(log_loss(y_val, valid_probs)))\n",
    "print('Validation Xception Accuracy {}'.format(accuracy_score((y_val * range(NUM_CLASSES)).sum(axis=1), valid_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from raw images\n",
      "All test Images shape: (10357, 299, 299, 3) size: 2,777,778,471\n",
      "10357/10357 [==============================] - 1000s  \n",
      "All test bottleneck features shape: (10357, 2048) size: 21,211,136\n",
      "Dumping into ../data//test//xs_bf_inception\n"
     ]
    }
   ],
   "source": [
    "# Get test bottelneck features\n",
    "INPUT_SIZE = 299\n",
    "POOLING = 'avg'\n",
    "filename = data_dir + '//test//xs_bf_inception'\n",
    "\n",
    "if isfile(filename):\n",
    "    print('File {} already exists!'.format(filename))\n",
    "else:\n",
    "    # Preprocess images\n",
    "    print('Reading from raw images')\n",
    "    xs = np.zeros((len(sample_submission.id), INPUT_SIZE, INPUT_SIZE, 3), dtype='float32')\n",
    "    for i, img_id in enumerate(sample_submission['id']):\n",
    "        img = read_img(img_id, 'test', (INPUT_SIZE, INPUT_SIZE))\n",
    "        x = inception_v3.preprocess_input(np.expand_dims(img.copy(), axis=0))\n",
    "        xs[i] = x\n",
    "    print('All test Images shape: {} size: {:,}'.format(xs.shape, xs.size))\n",
    "    \n",
    "    # Predict\n",
    "    preprocess_bottleneck = inception_v3.InceptionV3(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "    xs_bf_raw = preprocess_bottleneck.predict(xs, batch_size=6, verbose=1)\n",
    "    print('All test bottleneck features shape: {} size: {:,}'.format(xs_bf_raw.shape, xs_bf_raw.size))\n",
    "    xs_bf = pd.concat([sample_submission.id, pd.DataFrame(xs_bf_raw)], axis=1)\n",
    "    \n",
    "    # Save into file\n",
    "    print('Dumping into {}'.format(filename))\n",
    "    with open(filename, 'wb') as fp:\n",
    "        pickle.dump(xs_bf, fp)\n",
    "\n",
    "xs = None\n",
    "xs_bf = None\n",
    "xs_bf_raw = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
