{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a simple CNN from scratch\n",
    "It is not expected to have good results, as we are not using transfer learning here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical, plot_model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(img_id, train_or_test, size=None):\n",
    "    img = image.load_img(join(data_dir, train_or_test, '%s.jpg' % img_id), target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all train images: 10222\n",
      "Train data has 120 classes.\n",
      "Number of all test images: 10357\n",
      "y_tr shape: (8185, 120)\n",
      "y_val shape: (2037, 120)\n"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 120\n",
    "SEED = 1993\n",
    "np.random.seed(seed=SEED)\n",
    "data_dir = '../data'\n",
    "\n",
    "labels = pd.read_csv(join(data_dir, 'labels.csv'))\n",
    "print('Number of all train images: {}'.format(len(labels)))\n",
    "print(\"Train data has {} classes.\".format(len(labels.groupby('breed').count())))\n",
    "assert len(labels.groupby('breed').count()) == NUM_CLASSES, 'Number of classes in training set is not 120!'\n",
    "\n",
    "sample_submission = pd.read_csv(join(data_dir, 'sample_submission.csv'))\n",
    "print('Number of all test images: {}'.format(len(sample_submission)))\n",
    "\n",
    "# Split to train and validation sets\n",
    "l_val = labels.groupby('breed').apply(pd.DataFrame.sample, frac=0.2).reset_index(drop=True)\n",
    "l_tr = labels.loc[~labels['id'].isin(l_val['id'])]\n",
    "l_tr_index = {label:i for i,label in enumerate(np.unique(l_tr.breed))}\n",
    "l_tr_temp = [l_tr_index[label] for label in l_tr.breed]\n",
    "l_val_temp = [l_tr_index[label] for label in l_val.breed]\n",
    "y_tr = to_categorical(l_tr_temp ,num_classes=120)\n",
    "y_val = to_categorical(l_val_temp ,num_classes=120)\n",
    "print('y_tr shape: {}'.format(y_tr.shape))\n",
    "print('y_val shape: {}'.format(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_tr shape (8185, 120, 120, 3)\n",
      "x_val shape (2037, 120, 120, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load train images\n",
    "INPUT_SIZE = 120\n",
    "x_tr = np.zeros((len(l_tr), INPUT_SIZE, INPUT_SIZE, 3))\n",
    "for i, img_id in enumerate(l_tr.id):\n",
    "    x_tr[i] = read_img(img_id, 'train', size=(INPUT_SIZE, INPUT_SIZE))\n",
    "print(\"x_tr shape {}\".format(x_tr.shape))\n",
    "\n",
    "x_val = np.zeros((len(l_val), INPUT_SIZE, INPUT_SIZE, 3))\n",
    "for i, img_id in enumerate(l_val.id):\n",
    "    x_val[i] = read_img(img_id, 'train', size=(INPUT_SIZE, INPUT_SIZE))\n",
    "print(\"x_val shape {}\".format(x_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 118, 118, 22)      616       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 118, 118, 22)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 59, 59, 22)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 57, 57, 22)        4378      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 57, 57, 22)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 28, 28, 22)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 26, 26, 22)        4378      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 26, 26, 22)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 13, 13, 22)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3718)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               446280    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 120)               14520     \n",
      "=================================================================\n",
      "Total params: 470,172\n",
      "Trainable params: 470,172\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Setup model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(22, (3, 3), input_shape=(INPUT_SIZE, INPUT_SIZE, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(22, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(22, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(120, kernel_regularizer=l2(0.00001)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(120, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8185 samples, validate on 2037 samples\n",
      "Epoch 1/100\n",
      "8185/8185 [==============================] - 46s 6ms/step - loss: 15.9840 - acc: 0.0062 - val_loss: 15.9449 - val_acc: 0.0108\n",
      "Epoch 2/100\n",
      "8185/8185 [==============================] - 38s 5ms/step - loss: 9.4376 - acc: 0.0109 - val_loss: 4.7860 - val_acc: 0.0137\n",
      "Epoch 3/100\n",
      "8185/8185 [==============================] - 39s 5ms/step - loss: 4.7847 - acc: 0.0159 - val_loss: 4.7755 - val_acc: 0.0162\n",
      "Epoch 4/100\n",
      "8185/8185 [==============================] - 40s 5ms/step - loss: 4.7579 - acc: 0.0182 - val_loss: 4.7638 - val_acc: 0.0172\n",
      "Epoch 5/100\n",
      "8185/8185 [==============================] - 40s 5ms/step - loss: 4.7010 - acc: 0.0237 - val_loss: 4.7439 - val_acc: 0.0196\n",
      "Epoch 6/100\n",
      "8185/8185 [==============================] - 40s 5ms/step - loss: 4.6279 - acc: 0.0348 - val_loss: 4.7215 - val_acc: 0.0216\n",
      "Epoch 7/100\n",
      "8185/8185 [==============================] - 38s 5ms/step - loss: 4.5362 - acc: 0.0440 - val_loss: 4.7157 - val_acc: 0.0211\n",
      "Epoch 8/100\n",
      "8185/8185 [==============================] - 38s 5ms/step - loss: 4.4298 - acc: 0.0553 - val_loss: 4.7109 - val_acc: 0.0221\n",
      "Epoch 9/100\n",
      "8185/8185 [==============================] - 40s 5ms/step - loss: 4.3243 - acc: 0.0666 - val_loss: 4.7199 - val_acc: 0.0206\n",
      "Epoch 10/100\n",
      "8185/8185 [==============================] - 40s 5ms/step - loss: 4.1967 - acc: 0.0828 - val_loss: 4.7371 - val_acc: 0.0206\n",
      "Epoch 11/100\n",
      "8185/8185 [==============================] - 40s 5ms/step - loss: 4.0731 - acc: 0.1040 - val_loss: 4.7463 - val_acc: 0.0196\n",
      "Epoch 12/100\n",
      "8185/8185 [==============================] - 38s 5ms/step - loss: 3.9355 - acc: 0.1202 - val_loss: 4.8342 - val_acc: 0.0231\n",
      "Epoch 13/100\n",
      "8185/8185 [==============================] - 38s 5ms/step - loss: 3.8094 - acc: 0.1448 - val_loss: 4.8858 - val_acc: 0.0275\n",
      "Epoch 14/100\n",
      "8185/8185 [==============================] - 40s 5ms/step - loss: 3.6924 - acc: 0.1664 - val_loss: 4.9731 - val_acc: 0.0231\n",
      "Epoch 15/100\n",
      "8185/8185 [==============================] - 41s 5ms/step - loss: 3.5506 - acc: 0.1900 - val_loss: 4.9701 - val_acc: 0.0211\n",
      "Epoch 16/100\n",
      "8185/8185 [==============================] - 40s 5ms/step - loss: 3.4573 - acc: 0.1991 - val_loss: 5.0916 - val_acc: 0.0245\n",
      "Epoch 17/100\n",
      "8185/8185 [==============================] - 39s 5ms/step - loss: 3.3563 - acc: 0.2150 - val_loss: 5.1109 - val_acc: 0.0260\n",
      "Epoch 18/100\n",
      "8185/8185 [==============================] - 40s 5ms/step - loss: 3.2410 - acc: 0.2426 - val_loss: 5.3368 - val_acc: 0.0245\n",
      "Epoch 19/100\n",
      "8185/8185 [==============================] - 40s 5ms/step - loss: 3.1351 - acc: 0.2525 - val_loss: 5.4312 - val_acc: 0.0226\n",
      "Epoch 20/100\n",
      "8185/8185 [==============================] - 39s 5ms/step - loss: 3.0539 - acc: 0.2706 - val_loss: 5.3994 - val_acc: 0.0226\n",
      "Epoch 21/100\n",
      "8185/8185 [==============================] - 39s 5ms/step - loss: 2.9677 - acc: 0.2970 - val_loss: 5.5720 - val_acc: 0.0265\n",
      "Epoch 22/100\n",
      "2000/8185 [======>.......................] - ETA: 26s - loss: 2.8644 - acc: 0.3090"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-88f95dd1457e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m           \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m           shuffle=True)\n\u001b[0m",
      "\u001b[1;32mc:\\users\\tomas\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    958\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    959\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 960\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    961\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[1;32mc:\\users\\tomas\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1649\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1651\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mc:\\users\\tomas\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'size'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1213\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1214\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tomas\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2352\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2353\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tomas\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 889\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    890\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tomas\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1120\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tomas\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1315\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1317\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1318\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tomas\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1323\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1324\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\tomas\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[0;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m                                    status, run_metadata)\n\u001b[0m\u001b[0;32m   1303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(x_tr, y_tr,\n",
    "          validation_data=(x_val, y_val),\n",
    "          batch_size=100,\n",
    "          epochs=100,\n",
    "          verbose=1,\n",
    "          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8185/8185 [==============================] - 14s 2ms/step\n",
      "Final model train loss: 1.8943831761144034 | accuracy 0.6544899210816268\n",
      "2037/2037 [==============================] - 3s 2ms/step\n",
      "Final model val loss: 5.754765331013623 | accuracy 0.02405498255452047\n"
     ]
    }
   ],
   "source": [
    "loss_tr, acc_tr = model.evaluate(x_tr, y_tr, batch_size=100)\n",
    "print('Final model train loss: {} | accuracy {}'.format(loss_tr, acc_tr))\n",
    "\n",
    "loss_val, acc_val = model.evaluate(x_val, y_val, batch_size=100)\n",
    "print('Final model val loss: {} | accuracy {}'.format(loss_val, acc_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorry for the impatient interrupt. This is clearly not going anywhere. How surprising?!\n",
    "It is fun though, but it obviously cannot compare to dozen of conv layers and tons of train images of imagenet models.\n",
    "Also, I had to scale the image size down quite a bit to fit it into my laptop GPU.\n",
    "Next time, transfer learning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
