{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import _pickle as pickle\n",
    "from os import listdir\n",
    "from os.path import join, isfile\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "from keras import backend as K\n",
    "K.set_session(session)\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import to_categorical, plot_model\n",
    "\n",
    "from keras.applications import xception\n",
    "from keras.applications.xception import preprocess_input\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(img_id, train_or_test, size=None):\n",
    "    img = image.load_img(join(data_dir, train_or_test, '%s.jpg' % img_id), target_size=size)\n",
    "    img = image.img_to_array(img)\n",
    "    return img\n",
    "\n",
    "def augment(img):\n",
    "    images = np.zeros((NUM_AUGS, img.shape[0], img.shape[1], 3))\n",
    "    images[0] = img\n",
    "    \n",
    "    # Randomly add noice and change color for following augmentations\n",
    "    random_aug = iaa.OneOf([\n",
    "        iaa.Multiply((0.9, 1.1), per_channel=1),\n",
    "        iaa.AdditiveGaussianNoise(scale=(0.03*255, 0.08*255), per_channel=0.5)\n",
    "    ])\n",
    "    \n",
    "    # Flip horizontally\n",
    "    images[1] = iaa.Fliplr(1).augment_images([img])[0]\n",
    "    \n",
    "    # Rotate both flipped images\n",
    "    images[2] = iaa.Sequential([random_aug, iaa.Affine(rotate=(13, 16), mode='edge')]).augment_images([images[0]])[0]\n",
    "    images[3] = iaa.Sequential([random_aug, iaa.Affine(rotate=(-13, -16), mode='edge')]).augment_images([images[0]])[0]\n",
    "    images[4] = iaa.Sequential([random_aug, iaa.Affine(rotate=(13, 16), mode='edge')]).augment_images([images[1]])[0]\n",
    "    images[5] = iaa.Sequential([random_aug, iaa.Affine(rotate=(-13, -16), mode='edge')]).augment_images([images[1]])[0]\n",
    "    \n",
    "    # Shear both flipped images\n",
    "    images[6] = iaa.Sequential([random_aug, iaa.Affine(shear=(17, 22), mode='edge')]).augment_images([images[0]])[0]\n",
    "    images[7] = iaa.Sequential([random_aug, iaa.Affine(shear=(-17, -22), mode='edge')]).augment_images([images[0]])[0]\n",
    "    images[8] = iaa.Sequential([random_aug, iaa.Affine(shear=(17, 22), mode='edge')]).augment_images([images[1]])[0]\n",
    "    images[9] = iaa.Sequential([random_aug, iaa.Affine(shear=(-17, -22), mode='edge')]).augment_images([images[1]])[0]\n",
    "    \n",
    "    return images\n",
    "\n",
    "def add_augmented_labels(ls, inds):\n",
    "    temp_augs = np.tile(np.arange(NUM_AUGS), (len(inds), 1))\n",
    "    temp_inds = inds.values.reshape((len(inds), 1)) * NUM_AUGS\n",
    "    new_inds = np.add(temp_inds, temp_augs).reshape(len(inds)*NUM_AUGS)\n",
    "    new_ls = ls.reindex(np.repeat(ls.index.values, NUM_AUGS), method='ffill')\n",
    "    new_ls = new_ls.iloc[new_inds, :]\n",
    "    return new_ls, new_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of all train images: 10222\n",
      "Train data has 120 classes.\n",
      "Number of all test images: 10357\n",
      "y_tr shape: (81850, 120)\n",
      "y_val shape: (20370, 120)\n"
     ]
    }
   ],
   "source": [
    "# Load labels\n",
    "NUM_CLASSES = 120\n",
    "SEED = 1993\n",
    "NUM_AUGS = 10\n",
    "np.random.seed(seed=SEED)\n",
    "data_dir = '../data'\n",
    "\n",
    "labels = pd.read_csv(join(data_dir, 'labels.csv'))\n",
    "print('Number of all train images: {}'.format(len(labels)))\n",
    "print(\"Train data has {} classes.\".format(len(labels.groupby('breed').count())))\n",
    "assert len(labels.groupby('breed').count()) == NUM_CLASSES, 'Number of classes in training set is not 120!'\n",
    "\n",
    "sample_submission = pd.read_csv(join(data_dir, 'sample_submission.csv'))\n",
    "print('Number of all test images: {}'.format(len(sample_submission)))\n",
    "\n",
    "# Split to train and validation sets\n",
    "temp_labels_tr = labels.groupby('breed').apply(pd.DataFrame.sample, frac=0.8)\n",
    "temp_labels_val = labels.loc[~labels['id'].isin(temp_labels_tr['id'])]\n",
    "l_tr, inds_tr = add_augmented_labels(labels, temp_labels_tr.index.levels[1])\n",
    "l_val, inds_val = add_augmented_labels(labels, temp_labels_val.index)\n",
    "\n",
    "breed_index = {label:i for i,label in enumerate(np.unique(l_tr.breed))}\n",
    "l_tr_temp = [breed_index[label] for label in l_tr.breed]\n",
    "l_val_temp = [breed_index[label] for label in l_val.breed]\n",
    "y_tr = to_categorical(l_tr_temp ,num_classes=120)\n",
    "y_val = to_categorical(l_val_temp ,num_classes=120)\n",
    "\n",
    "print('y_tr shape: {}'.format(y_tr.shape))\n",
    "print('y_val shape: {}'.format(y_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from ../data//train//xs_bf_xception_aug\n",
      "xs_bf shape: (102220, 2049) size: 209,448,780\n",
      "Train bottleneck features shape: (81850, 2048) size: 167,628,800\n",
      "Validation bottleneck features shape: (20370, 2048) size: 41,717,760\n"
     ]
    }
   ],
   "source": [
    "# Get bottelneck features\n",
    "INPUT_SIZE = 299\n",
    "POOLING = 'avg'\n",
    "filename = data_dir + '//train//xs_bf_xception_aug'\n",
    "\n",
    "if isfile(filename):\n",
    "    # Load from file\n",
    "    print('Loading from {}'.format(filename))\n",
    "    with open(filename, 'rb') as fp:\n",
    "        xs_bf = pickle.load(fp)\n",
    "    print('xs_bf shape: {} size: {:,}'.format(xs_bf.shape, xs_bf.size))\n",
    "else:\n",
    "    # Preprocess images\n",
    "    preprocess_bottleneck = xception.Xception(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "    \n",
    "    for i, img_id in enumerate(labels['id']):\n",
    "        \n",
    "        # Read image\n",
    "        img = read_img(img_id, 'train', (INPUT_SIZE, INPUT_SIZE))\n",
    "        \n",
    "        # Augment image\n",
    "        images = augment(img)\n",
    "        \n",
    "        # Preprocess to model's liking (usually scales down to 0-1 range)\n",
    "        images = map(lambda au_img: preprocess_input(np.expand_dims(au_img.copy(), axis=0)), images)\n",
    "        images = np.asarray(list(images)).reshape((10, INPUT_SIZE, INPUT_SIZE, 3))\n",
    "        \n",
    "        # Retrieve bottleneck features\n",
    "        x_bf_raw = preprocess_bottleneck.predict(images, batch_size=int(NUM_AUGS/2))\n",
    "        \n",
    "        # Store bottleneck features in xs_bf DataFrame\n",
    "        x_bf = pd.DataFrame(x_bf_raw)\n",
    "        x_bf['id'] = img_id\n",
    "        if i == 0:\n",
    "            xs_bf = x_bf\n",
    "        else:\n",
    "            xs_bf = pd.concat([xs_bf, x_bf], axis=0)\n",
    "            \n",
    "        if i % 100 == 0:\n",
    "            print('Iteration {:5d} | Bottlenecks shape: {} size: {}'.format(i, xs_bf.shape, xs_bf.size))\n",
    "    print('All train bottleneck features shape: {} size: {:,}'.format(xs_bf.shape, xs_bf.size))\n",
    "    \n",
    "    # Save into file\n",
    "    print('Dumping into {}'.format(filename))\n",
    "    with open(filename, 'wb') as fp:\n",
    "        pickle.dump(xs_bf, fp)\n",
    "\n",
    "# Split to train/val sets\n",
    "x_tr = xs_bf.values[inds_tr, :-1]\n",
    "print('Train bottleneck features shape: {} size: {:,}'.format(x_tr.shape, x_tr.size))\n",
    "\n",
    "x_val = xs_bf.values[inds_val, :-1]\n",
    "print('Validation bottleneck features shape: {} size: {:,}'.format(x_val.shape, x_val.size))\n",
    "\n",
    "x_bf_raw = None\n",
    "xs_bf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select original images for model comparison\n",
    "x_tr_orig = x_tr[::10]\n",
    "x_val_orig = x_val[::10]\n",
    "y_tr_orig = y_tr[::10]\n",
    "y_val_orig = y_val[::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=1993, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic regression on all augmented images\n",
    "logreg_aug = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\n",
    "logreg_aug.fit(x_tr, (y_tr * range(NUM_CLASSES)).sum(axis=1))\n",
    "\n",
    "# Logistic regression on original images only\n",
    "logreg_orig = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=SEED)\n",
    "logreg_orig.fit(x_tr_orig, (y_tr_orig * range(NUM_CLASSES)).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = []\n",
    "acc = []\n",
    "models = [logreg_orig, logreg_aug]\n",
    "\n",
    "for i in range(2):\n",
    "    model = models[i]\n",
    "    loss.append([])\n",
    "    acc.append([])\n",
    "    \n",
    "    # validate on all images\n",
    "    xv = x_val\n",
    "    yv = y_val\n",
    "    valid_probs = model.predict_proba(xv)\n",
    "    loss[i].append(log_loss(yv, valid_probs))\n",
    "    acc[i].append(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), np.argmax(valid_probs, axis=1)))\n",
    "\n",
    "    # validate on original images\n",
    "    xv = x_val_orig\n",
    "    yv = y_val_orig\n",
    "    valid_probs = model.predict_proba(xv)\n",
    "    loss[i].append(log_loss(yv, valid_probs))\n",
    "    acc[i].append(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), np.argmax(valid_probs, axis=1)))\n",
    "\n",
    "    # validate on all images and average the predictions\n",
    "    xv = x_val\n",
    "    yv = y_val_orig\n",
    "    valid_probs = model.predict_proba(xv)\n",
    "    valid_probs = np.mean(valid_probs.reshape((int(valid_probs.shape[0]/10), 10, 120)), axis=1)\n",
    "    valid_probs = valid_probs / np.sum(valid_probs, axis=0)\n",
    "    loss[i].append(log_loss(yv, valid_probs))\n",
    "    acc[i].append(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), np.argmax(valid_probs, axis=1)))\n",
    "\n",
    "    # validate on original and flipped images, then average predictions\n",
    "    xv = np.concatenate((x_val[::10], x_val[1::10]))\n",
    "    yv = y_val_orig\n",
    "    valid_probs = model.predict_proba(xv)\n",
    "    valid_probs = np.concatenate((valid_probs[:int(valid_probs.shape[0]/2)], valid_probs[int(valid_probs.shape[0]/2):]), axis=1)\n",
    "    valid_probs = np.mean(valid_probs.reshape((int(valid_probs.shape[0]), 2, 120)), axis=1)\n",
    "    valid_probs = valid_probs / np.sum(valid_probs, axis=0)\n",
    "    loss[i].append(log_loss(yv, valid_probs))\n",
    "    acc[i].append(accuracy_score((yv * range(NUM_CLASSES)).sum(axis=1), np.argmax(valid_probs, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Original  |  Augmented\n",
      " loss  acc  |  loss  acc  \n",
      "0.588 82.6% | 0.613 83.4% <- validate on all images\n",
      "0.330 89.2% | 0.395 88.6% <- validate on original images\n",
      "0.412 88.6% | 0.399 87.8% <- validate on all images and average the predictions\n",
      "0.312 89.8% | 0.357 89.1% <- validate on original and flipped images, then average predictions\n"
     ]
    }
   ],
   "source": [
    "notes = [\n",
    "    'validate on all images',\n",
    "    'validate on original images',\n",
    "    'validate on all images and average the predictions',\n",
    "    'validate on original and flipped images, then average predictions'\n",
    "]\n",
    "print('  Original  |  Augmented')\n",
    "print(' loss  acc  |  loss  acc  ')\n",
    "for i in range(len(loss[0])):\n",
    "    print('{:.3f} {:.1%} | {:.3f} {:.1%} <- {}'.format(loss[0][i], acc[0][i], loss[1][i], acc[1][i], notes[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up here it looks sad. Augmentation actually makes it worse.\n",
    "\n",
    "My guess is that it actually increases overfitting because the augmented bottleneck features are too similar to the original. Further exploration in xception augmented notebook.\n",
    "\n",
    "Note that the best performance is achieved by the original model when evaluated on 2 (original and flipped) images. This was also discovered in the xception augmented notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test bottelneck features\n",
    "INPUT_SIZE = 299\n",
    "POOLING = 'avg'\n",
    "filename = data_dir + '//test//xs_bf_xception_aug'\n",
    "\n",
    "if isfile(filename):\n",
    "    print('File {} already exists!'.format(filename))\n",
    "else:\n",
    "    # Preprocess images\n",
    "    preprocess_bottleneck = xception.Xception(weights='imagenet', include_top=False, pooling=POOLING)\n",
    "    \n",
    "    for i, img_id in enumerate(sample_submission['id']):\n",
    "        \n",
    "        # Read image\n",
    "        img = read_img(img_id, 'test', (INPUT_SIZE, INPUT_SIZE))\n",
    "        \n",
    "        # Augment image - Not for test images!\n",
    "        images = [img]\n",
    "        \n",
    "        # Preprocess to model's liking (usually scales down to 0-1 range)\n",
    "        x = list(map(lambda au_img: preprocess_input(np.expand_dims(au_img.copy(), axis=0)), images))\n",
    "        \n",
    "        # Retrieve bottleneck features\n",
    "        x_bf_raw = preprocess_bottleneck.predict(x, batch_size=1)\n",
    "        \n",
    "        # Store bottleneck features in xs_bf DataFrame\n",
    "        x_bf = pd.DataFrame(x_bf_raw)\n",
    "        x_bf['id'] = img_id\n",
    "        if i == 0:\n",
    "            xs_bf = x_bf\n",
    "        else:\n",
    "            xs_bf = pd.concat([xs_bf, x_bf], axis=0)\n",
    "            \n",
    "        if i % 100 == 0:\n",
    "            print('Iteration {:5d} | Bottlenecks shape: {} size: {}'.format(i, xs_bf.shape, xs_bf.size))\n",
    "    print('All test bottleneck features shape: {} size: {:,}'.format(xs_bf.shape, xs_bf.size))\n",
    "    \n",
    "    # Save into file\n",
    "    print('Dumping into {}'.format(filename))\n",
    "    with open(filename, 'wb') as fp:\n",
    "        pickle.dump(xs_bf, fp)\n",
    "\n",
    "x_bf_raw = None\n",
    "xs_bf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
